Crawler
================

## Features
- Maximum crawling depth, pages
- Repects robots.txt
- Able to crawler AJAX pages (crawler-ajax.py)

The overall dataflow for the crawling processing looks like:

![Alt text](architecture-scrapy.png "Architecture")

## Requirements
- Scrapy

## Usage

```
scrapy crawl mycrawler
```

## Reference

The building of this crawler follows instructions from [CS101 in Udacity](https://www.udacity.com/course/viewer#!/c-cs101) and [DaveDaveFind](http://davedavefind.appspot.com/).

Auto
================

## Requirements
- Python v2.7+
- vmauto.py
- [Python for Windows extensions](http://sourceforge.net/projects/pywin32/)

## Usage

```
python auto.py filename.exe
```

## Reference

The automation is based on [Simon Brunning's winGuiAuto.py](http://www.brunningonline.net/simon/blog/archives/winGuiAuto.py.html)
